## Definition

The more well accepted definition of machine learning is that "It is a computer program which is said to learn from experience E with respect to some class of tasks T and performance measure P, if its performance at tasks in T, as measured by P, improves with experience E"

## Understanding

It is usual in ML space that every task has to deal with a large amount of data at hand. Obviously one doesn't want to let his/her program visit each and every data entity and take years of time to do a simple task.

Thus, it is important to learn few alternatives to represent this huge data in more simple and descriptive ways. This is where **statistics** can play a pivotal role.

Let's start with simple stuff. Say you have a large collection of numbers, may be the age of people across the world. And lets say we are curious to find what is the avergae age that the people are living in the world. If someone needs to look at each and every person's age to come to valid conclusion then definitely it will take a lot of time.

Statistics comes handy in this context. It helps us to represent the whole collection of numbers into a simple concept called "central tendency".

In statistics, the 3 basic ways in which "central tendancy" can be expressed are:

* Mean (more specifically Arithmetic Mean)
* Median
* Mode
